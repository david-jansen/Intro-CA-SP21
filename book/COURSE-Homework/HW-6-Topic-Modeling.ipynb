{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6 — Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Your name here  \n",
    "Net ID: Your ID here\n",
    "(Double-click this cell to type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In this homework assignment, you will be topic modeling a collection of Reddit posts to understand 15 of its broad themes and trends. You will choose to analyze either a collection of posts from the subreddit [r/pettyrevenge](https://www.reddit.com/r/pettyrevenge/) OR the subreddit [r/AskScience](https://www.reddit.com/r/askscience/).\n",
    "\n",
    "*Note: Posts from r/pettyrevenge may be offensive or inapproriate.*\n",
    "\n",
    "This homework assignment will closely mirror our 05-Text-Analysis/04.5 class workbook from Monday, April 12th. It will also include basic Python and Pandas concepts from the previous weeks. You are encouraged to refer back to your class workbooks and the course textbook.\n",
    "\n",
    "When you're finished, please upload this Jupyer notebook to Gradescope (LAST-NAME-HW-6.ipynb).\n",
    "\n",
    "*Note: If you're having trouble running Little Mallet Wrapper on your own computer, you can complete this homework assignment in the cloud [via Binder](https://mybinder.org/v2/gh/INFO1350/Intro-CA-SP21/master?urlpath=lab/tree/book/COURSE-Homework/HW-6-Topic-Modeling.ipynb) and then download it (File -> Download).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['AITA for kicking my cousin off of my sister’s wedding Zoom call?',\n",
    " 'AITA for resenting my family for something that happened over a decade ago?',\n",
    " 'AITA for cutting the power to a little girl’s birthday party?',\n",
    " 'AITA for keeping a $300000 prize to myself when I originally planned to share it with my boyfriend?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Transform each title in `titles` to lowercase, and make a new list of the lowercased titles called `lowercase_titles`. To do so, use a [list comprehension](https://www.w3schools.com/python/python_lists_comprehension.asp) (that is, just one line of Python code). (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_titles = #Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aita for kicking my cousin off of my sister’s wedding zoom call?', 'aita for resenting my family for something that happened over a decade ago?', 'aita for cutting the power to a little girl’s birthday party?', 'aita for keeping a $300000 prize to myself when i originally planned to share it with my boyfriend?']\n"
     ]
    }
   ],
   "source": [
    "print(lowercase_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Install `little_mallet_wrapper` (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Import `little_mallet_wrapper`, `pandas`, and `Path`  (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "#Your code here\n",
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Training Data From CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will read in the CSV file for the subreddit [r/pettyrevenge](https://www.reddit.com/r/pettyrevenge/) OR the subreddit [r/AskScience](https://www.reddit.com/r/askscience/). To get the r/AskScience data, you will need to uncomment and run the second line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(\"../data/top-reddit-petty-revenge-posts.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit_df = pd.read_csv(\"../data/top-reddit-ask-science-posts.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows are in this DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Convert the `selftext` column to the datatype *string* and re-assign it to the same column  (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['selftext'] = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Reddit Posts and Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Transform all the Reddit posts to lowercase and remove stopwords, punctuation, and numbers. To do so, you should use a `little_mallet_wrapper` function and a list comprehension (just one line of code)  (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of the original Reddit posts (completed for you below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_texts = [text for text in reddit_df['selftext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Make a list of every title from the DataFrame in the column `title` and assign it to the variable `reddit_titles` (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_titles = #Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Number of Topics and Output Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a variable `num_topics` and assign it the number of topics we want returned (completed for you below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell Little MALLET Wrapper where to output all of your topic modeling results. To do so, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No need to change anything below here\n",
    "training_data = training_data\n",
    "\n",
    "#Set output directory\n",
    "output_directory_path = 'topic-model-output/HW-6'\n",
    "\n",
    "#Create output directory\n",
    "Path(f\"{output_directory_path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#Create output files\n",
    "path_to_training_data           = f\"{output_directory_path}/training.txt\"\n",
    "path_to_formatted_training_data = f\"{output_directory_path}/mallet.training\"\n",
    "path_to_model                   = f\"{output_directory_path}/mallet.model.{str(num_topics)}\"\n",
    "path_to_topic_keys              = f\"{output_directory_path}/mallet.topic_keys.{str(num_topics)}\"\n",
    "path_to_topic_distributions     = f\"{output_directory_path}/mallet.topic_distributions.{str(num_topics)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Set `path_to_mallet` to the file path where Mallet is located on your computer (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mallet = '../05-Text-Analysis/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The file path above should work for Binder, but if you're working on your own computer, you may need to change the path.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the topic model with `little_mallet_wrapper.quick_train_topic_model()`. Remember that this may take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "little_mallet_wrapper.quick_train_topic_model(path_to_mallet,\n",
    "                                              output_directory_path,\n",
    "                                              num_topics,\n",
    "                                              training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint: If you get the error `No such file or directory: 'topic-model-output/HW-6/mallet.topic_keys.15`, then Java/Mallet is likely not configured properly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Topics and Top Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Display the 15 topics by running the cell below (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = little_mallet_wrapper.load_topic_keys(path_to_topic_keys)\n",
    "\n",
    "for topic_number, topic in enumerate(topics):\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Topic Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the topic distributions for all the documents (the probability that each document contains each of the topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distributions = little_mallet_wrapper.load_topic_distributions(path_to_topic_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Top Titles and Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to create the two functions that will help you examine the top Reddits posts for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip together the training data (pre-processed docs) and titles/original texts and make them dictionaries\n",
    "training_data_reddit_titles = dict(zip(training_data, reddit_titles))\n",
    "training_data_original_text = dict(zip(training_data, original_texts))\n",
    "\n",
    "#Create a function for displaying the top titles\n",
    "def display_top_titles_per_topic(topic_number=0, number_of_documents=5):\n",
    "    \n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "        print(round(probability, 4), training_data_reddit_titles[document] + \"\\n\")\n",
    "    return\n",
    "\n",
    "#Create a function for displaying topics words in context\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "\n",
    "def display_bolded_topic_words_in_context(topic_number=3, number_of_documents=3):\n",
    "\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topics[topic_number]}\\n\")\n",
    "    for probability, document in little_mallet_wrapper.get_top_docs(training_data, topic_distributions, topic_number, n=number_of_documents):\n",
    "        probability = f\"✨✨✨\\n\\n{probability}\"\n",
    "        obit_title = f\"#### {training_data_reddit_titles[document]}\"\n",
    "        original_text = training_data_original_text[document]\n",
    "        topic_words = topics[topic_number]\n",
    "\n",
    "        for word in topic_words:\n",
    "            if word in original_text.lower():\n",
    "                original_text = re.sub(f\"\\\\b{word}\\\\b\", f\"**{word}**\", original_text, flags=re.IGNORECASE)\n",
    "\n",
    "        display(Markdown(probability)), display(Markdown(obit_title)), display(Markdown(original_text))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** By using one of the functions above, display the top 5 Reddit titles with the highest probability of containing Topic 0 (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** By using one of the functions above, display the top 5 Reddit posts with bolded words in context that have the highest probability of containing Topic 0 (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label the Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** By using the functions above and examining the top documents for each topic, come up with your own labels for the 15 topics. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topic 0**: Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 1**: Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 2**: Paste top 5 words here    \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 3**: Paste top 5 words here   \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 4**:  Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 5**:  Paste top 5 words here    \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 6**:   Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 7**:  Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 8**:  Paste top 5 words here    \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 9**:  Paste top 5 words here   \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 10**:    Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 11**:  Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 12**: Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 13**:   Paste top 5 words here  \n",
    "**Topic Label**: ?\n",
    "\n",
    "**Topic 14**: Paste top 5 words here   \n",
    "**Topic Label**: ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** What do you think was the most interesting topic from the Reddit posts? Why? (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your thoughts here (double-click to type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.** What was the most difficult topic to label? Why?  (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your thoughts here (double-click to type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When You're Finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're finished, you should:\n",
    "\n",
    "1. Save your Jupyter notebook with your last name. To save your notebook, you can select File -> Save Notebook or File -> Save Notebook As...\n",
    "\n",
    "2. Upload the Jupyter notebook file (.ipynb) to Gradescope. You can do so by locating your file on your computer and then dragging and dropping it into Gradescope.\n",
    "\n",
    "![](../images/submit-hw-gradescope.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
