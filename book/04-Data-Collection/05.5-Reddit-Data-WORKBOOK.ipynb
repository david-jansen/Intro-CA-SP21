{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Collection — Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Don't forget to rename this notebook if you want to save changes!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we're going to introduce learn how to collect Reddit posts with the API wrapper known as [PSAW](https://github.com/dmarx/psaw)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why do people use Pushshift’s API instead of the official Reddit API?\n",
    "\n",
    "> In short, Pushshift makes it\n",
    "much easier for researchers to query and retrieve historical\n",
    "Reddit data, provides extended functionality by providing fulltext search against comments and submissions, and has larger\n",
    "single query limits. \n",
    "\n",
    ">— Jason Baumgartner, et al., [\"The Pushshift Reddit Dataset\"](https://arxiv.org/pdf/2001.08435.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install PSAW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to install the PSAW package with pip. The `!` allows us to run a command that is normally used on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install psaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will import pandas and set the default display options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth =  400\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will import a specific part of the PSAW package, PushshiftAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will \"initialize\" the PushshiftAPI, so we can work with it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Reddit submissions for a subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way PSAW works is a little unique. First, we will set up an \"API request generator,\" then we will loop through the generator to extract individual Reddit posts."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "api.search_submissions(subreddit = subreddit_of_interest,\n",
    "                        q = word_mentioned_in_submission, \n",
    "                        score = upvote_score_threshold, \n",
    "                        limit = number_of_submissions_to_return, \n",
    "                        before = search_submissions_before_epoch,\n",
    "                        after = search_submissions_before_epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_generator = api.search_submissions(subreddit='TodayILearned',\n",
    "                                               score = \">10000\",\n",
    "                                               limit=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract individual Reddit posts from the API request generator, extracting the data, which is stored in the attribute `submission.d_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submissions = []\n",
    "for submission in api_request_generator:\n",
    "    all_submissions.append(submission.d_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we calculate the length of the list `all_submissions`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we examine the first item in the list `all_submissions`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we create a DataFrame from `all_submissions`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions = pd.DataFrame(all_submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do all of the above in a single line of code, like so:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reddit_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reddit_submissions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what columns/metdata exist in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions[['title', 'score']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the `created_utc` column to a normal date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions['date'] = pd.to_datetime(reddit_submissions['created_utc'], utc=True, unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [],
   "source": [
    "reddit_submissions = reddit_submissions[['date','score', 'title', 'author', 'selftext',\n",
    "                  'url', 'subreddit',  'num_comments',\n",
    "                  'num_crossposts']]\n",
    "reddit_submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame to look at the top 10 Reddit posts with the highest upvote score (note that upvote score is stored in the colum `score`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose your own subreddit to collect data from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = 'CHOOSE YOUR OWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_generator = api.search_submissions(subreddit=subreddit,\n",
    "                                               score = \">3000\", limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "reddit_submissions['date'] = pd.to_datetime(reddit_submissions['created_utc'], utc=True, unit='s')\n",
    "reddit_submissions = reddit_submissions[['date','score', 'title', 'author', 'selftext',\n",
    "                  'url', 'subreddit',  'num_comments',\n",
    "                  'num_crossposts']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the DataFrame to look at the 10 Reddit posts with the highest upvote score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Reddit submissions based on search keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now search through Reddit posts based on a query word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'CHOOSE YOUR OWN QUERY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_generator = api.search_submissions(q= query,\n",
    "                                                score = \">2000\", limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "reddit_submissions['date'] = pd.to_datetime(reddit_submissions['created_utc'], utc=True, unit='s')\n",
    "reddit_submissions = reddit_submissions[['date','score', 'title', 'author', 'selftext',\n",
    "                  'url', 'subreddit',  'num_comments',\n",
    "                  'num_crossposts']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the subreddits where this query word appears (aka find the number of unique values for subreddits, which is stored in the column `subreddit`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_submissions..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus (If You Finish Early or Want to Explore More)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Reddit *comments* based on search keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_generator = api.search_comments(q='Missy Elliott',\n",
    "                                            score = \">2000\")\n",
    "reddit_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "reddit_submissions['date'] = pd.to_datetime(reddit_submissions['created_utc'], utc=True, unit='s')\n",
    "reddit_submissions = reddit_submissions[['date','score', 'subreddit','body', 'author']]\n",
    "reddit_submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Reddit submissions/comments based on multiple search keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for multiple phrases —  George Orwell OR J.R.R. Tolkein — use parentheses and the bitwise OR operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_generator = api.search_comments(q='(George Orwell)|(J. R. R. Tolkien)', limit=100)\n",
    "reddit_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "reddit_submissions['date'] = pd.to_datetime(reddit_submissions['created_utc'], utc=True, unit='s')\n",
    "reddit_submissions = reddit_submissions[['date','score', 'subreddit','body', 'author']]\n",
    "reddit_submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for multiple phrases —  Shakespeare AND Beyonce — use parentheses and the bitwise AND operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_request_generator = api.search_comments(q='(Shakespeare)&(Beyonce)')\n",
    "reddit_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "reddit_submissions['date'] = pd.to_datetime(reddit_submissions['created_utc'], utc=True, unit='s')\n",
    "reddit_submissions = reddit_submissions[['date','score', 'subreddit','body', 'author']]\n",
    "reddit_submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Reddit submissions/comments with start and end dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From January 1, 2020 to January 10, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "start_epoch=int(dt.datetime(2020, 1, 1).timestamp())\n",
    "end_epoch=int(dt.datetime(2020, 1, 10).timestamp())\n",
    "\n",
    "api_request_generator = api.search_comments(q='(Shakespeare)&(Beyonce)\"', after = start_epoch, before=end_epoch)\n",
    "reddit_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "reddit_submissions['date'] = pd.to_datetime(reddit_submissions['created_utc'], utc=True, unit='s')\n",
    "reddit_submissions = reddit_submissions[['date','score', 'subreddit','body', 'author']]\n",
    "reddit_submissions.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
